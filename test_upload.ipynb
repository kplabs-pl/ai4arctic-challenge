{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9662657d-0ee6-408d-94fe-da71539dcfd5",
   "metadata": {},
   "source": [
    "# AutoICE - test model and prepare upload package\n",
    "This notebook tests the 'best_model', created in the quickstart notebook, with the tests scenes exempt of reference data. The model outputs are stored per scene and chart in an xarray Dataset in individual Dataarrays. The xarray Dataset is saved and compressed in an .nc file ready to be uploaded to the AI4EO.eu platform. Finally, the scene chart inference is shown.\n",
    "\n",
    "The first cell imports necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cabf3fe-44c3-42f0-b061-5a70b64379be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Built-in modules -- #\n",
    "import os\n",
    "\n",
    "# -- Third-part modules -- #\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import xarray as xr\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --Proprietary modules -- #\n",
    "from functions import chart_cbar, r2_metric, f1_metric, compute_metrics\n",
    "from loaders import AI4ArcticChallengeTestDataset\n",
    "from unet import UNet\n",
    "from utils import CHARTS, SIC_LOOKUP, SOD_LOOKUP, FLOE_LOOKUP, SCENE_VARIABLES, colour_str\n",
    "%store -r train_options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b270975-ef64-45c0-bfa0-5f3d48504ab5",
   "metadata": {},
   "source": [
    "### Setup of the GPU resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e19a1-76d0-4047-b4a4-8b5f8af19bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GPU resources.\n",
    "if torch.cuda.is_available():\n",
    "    print(colour_str('GPU available!', 'green'))\n",
    "    print('Total number of available devices: ', colour_str(torch.cuda.device_count(), 'orange'))\n",
    "    device = torch.device(f\"cuda:{train_options['gpu_id']}\")\n",
    "\n",
    "else:\n",
    "    print(colour_str('GPU not available.', 'red'))\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d365e-0a78-43f2-9182-776148c80d31",
   "metadata": {},
   "source": [
    "### Load the model and stored parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e164255-8528-46b3-9ce6-6bc27c0effae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading model.')\n",
    "# Setup U-Net model, adam optimizer, loss function and dataloader.\n",
    "net = UNet(options=train_options).to(device)\n",
    "net.load_state_dict(torch.load('best_model')['model_state_dict'])\n",
    "print('Model successfully loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16af23-a901-4ca6-8d75-7a54d66a1eaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare the scene list, dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f92af3-32ab-4752-832a-29b5972ac375",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_options['path_to_env'] + 'datalists/testset.json') as file:\n",
    "    train_options['test_list'] = json.loads(file.read())\n",
    "train_options['test_list'] = [file[17:32] + '_' + file[77:80] + '_prep.nc' for file in train_options['test_list']]\n",
    "train_options['path_to_processed_data'] += 'test_data'  # The test data is stored in a separate folder inside the training data.\n",
    "upload_package = xr.Dataset()  # To store model outputs.\n",
    "dataset = AI4ArcticChallengeTestDataset(options=train_options, files=train_options['test_list'], test=True)\n",
    "asid_loader = torch.utils.data.DataLoader(dataset, batch_size=None, num_workers=train_options['num_workers_val'], shuffle=False)\n",
    "print('Setup ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20730e27-e0cc-4c1a-87a8-f2145d32f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing.')\n",
    "os.makedirs('inference', exist_ok=True)\n",
    "net.eval()\n",
    "for inf_x, _, masks, scene_name in tqdm(iterable=asid_loader, total=len(train_options['test_list']), colour='green', position=0):\n",
    "    scene_name = scene_name[:19]  # Removes the _prep.nc from the name.\n",
    "    torch.cuda.empty_cache()\n",
    "    inf_x = inf_x.to(device, non_blocking=True)\n",
    "\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        output = net(inf_x)\n",
    "\n",
    "    for chart in train_options['charts']:\n",
    "        output[chart] = torch.argmax(output[chart], dim=1).squeeze().cpu().numpy()\n",
    "        upload_package[f\"{scene_name}_{chart}\"] = xr.DataArray(name=f\"{scene_name}_{chart}\", data=output[chart].astype('uint8'),\n",
    "                                                               dims=(f\"{scene_name}_{chart}_dim0\", f\"{scene_name}_{chart}_dim1\"))\n",
    "\n",
    "    # - Show the scene inference.\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "    for idx, chart in enumerate(train_options['charts']):\n",
    "        ax = axs[idx]\n",
    "        output[chart] = output[chart].astype(float)\n",
    "        output[chart][masks] = np.nan\n",
    "        ax.imshow(output[chart], vmin=0, vmax=train_options['n_classes'][chart] - 2, cmap='jet', interpolation='nearest')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        chart_cbar(ax=ax, n_classes=train_options['n_classes'][chart], chart=chart, cmap='jet')\n",
    "    \n",
    "    plt.suptitle(f\"Scene: {scene_name}\", y=0.65)\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.5, hspace=-0)\n",
    "    fig.savefig(f\"inference/{scene_name}.png\", format='png', dpi=128, bbox_inches=\"tight\")\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "# - Save upload_package with zlib compression.\n",
    "print('Saving upload_package. Compressing data with zlib.')\n",
    "compression = dict(zlib=True, complevel=1)\n",
    "encoding = {var: compression for var in upload_package.data_vars}\n",
    "upload_package.to_netcdf('upload_package.nc', mode='w', format='netcdf4', engine='netcdf4', encoding=encoding)\n",
    "print('Testing completed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
